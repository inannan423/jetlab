# TreeSketchNet: 从素描到3D树参数生成

作者吉尔达·曼弗雷迪（Gilda Manfredi），尼古拉·卡佩切（Nicola Capece），乌戈·埃拉（Ugo Erra），莫妮卡·格鲁奥索（Monica Gruosso）<br />巴西利卡塔大学<br />数学、计算机科学和经济学系<br />意大利波坦察<br />{gilda.manfredi, nicola.capece, ugo.erra, monica.gruosso}@unibas.it
<a name="lWUaH"></a>
## 摘要
对于计算机图形领域的专业人士而言，从风格化草图中进行非线性对象的3D建模是一项具有挑战性的任务。从风格化草图中推导对象参数是一项非常复杂且繁琐的任务。在本研究中，我们提出了一种经纪系统，该系统在建模师和3D建模软件之间进行中介，能够将一棵树的风格化草图转化为完整的3D模型。输入草图不需要准确或详细，只需代表建模师希望进行3D建模的树的基本轮廓。我们的方法基于一个明确定义的深度神经网络（DNN）架构，我们称之为TreeSketchNet（TSN），基于卷积，能够生成可以被建模软件解释的Weber和Penn [1]参数，从而从简单的草图开始生成树的3D模型。训练数据集包括与Blender建模软件附加组件生成的Weber-Penn参数相关联的合成生成（SG）草图。通过对TSN使用合成和手绘草图的测试，验证了所提方法的准确性。最后，通过评估预测参数与多个显著特征的一致性，提供了对结果的定性分析。
<a name="zhlde"></a>
## 关键词
计算方法学 · 计算机图形学 · 形状建模 · 图像和视频采集 · 3D成像
<a name="lEe2u"></a>
## 1 Introduction
手动对具有非线性复杂3D结构特征的对象进行网格建模仍然是计算机图形领域专家的一个挑战。通常，诸如树木之类的对象使用过程建模[2]进行设计，该方法允许用户操纵特定的参数[3, 4, 5]以描述它们，避免直接编辑它们的几何形状。然而，影响这些对象的规则的复杂性意味着参数集不仅非常庞大，而且非线性。绘制目标3D对象通常比手动重建或对其几何形状进行参数化建模更容易且更直观。有几种基于图像的方法可以将真实对象重建为3D模型，例如基于摄影测量学[6, 7]和新技术如深度摄像头[8, 9]、LiDAR[10, 11]、激光扫描[12]等的方法。尽管有几种方法使用图像直接预测粗糙的3D网格[13, 14, 15, 16]，但许多方法产生不准确的结果，包括平滑或非常高面片数的网格、错误闭合的孔、非流形边和顶点以及孤立的顶点。为了克服这些问题，一些方法旨在使用图像自动化过程建模以预测参数[17, 18, 19]。与先前的方法一致，我们引入了一个经纪系统，位于3D建模师和用于构建3D树的专业3D建模软件之间。用户只需提供手绘（HM）草图作为输入；然后，经纪系统提供可以被3D建模软件读取的参数，并用于构建与草图尽可能相似的3D树。此外，我们的经纪系统还可以提供用于渲染3D树的适当纹理。我们经纪系统的关键元素是基于卷积的神经网络，该网络使用监督学习范例进行训练，能够学习参数映射并分析基于一组训练数据的草图。由于收集足够数量的手绘草图是一项非常昂贵的操作，我们开发了一个特定的Blender附加组件。这个附加组件称为Render Tree（RT），它基于现有的Blender Sapling Tree Gen 1，采用Weber和Penn [1]的过程建模方法来创建一组参数的3D树。这种方法的好处在于它可以创建一个一致的合成生成（SG）草图的训练数据集，如图1所示（例如，枫树）。尽管Weber和Penn是一个相当古老的模型，但其稳定性以及广泛的实现代码可用性使其仍然广泛用于参数化生成植物等3D模型[20, 21, 22, 23]。我们的实验评估了五种树木物种：枫树、松树、盆景、棕榈树和樱桃树。每种树木都收集了四个摄像机视图：前、后、左和右。在最后一步，通过变化RT Blender附加组件的输入参数，我们生成了每个树木物种的250个随机控制版本，共产生了5000个SG。值得注意的是，我们的数据集可以扩展到包括其他树种。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1704337618436-4495871a-3020-4bb5-8994-d71fa05f2461.png#averageHue=%23d6d3d2&clientId=uc6ee5aa7-2d91-4&from=paste&height=222&id=ud6b3c94a&originHeight=278&originWidth=796&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=191609&status=done&style=none&taskId=u0d6325ac-2f35-46c0-bba5-81d80855ca3&title=&width=636.8)
> 图1：重建的3D树以从不同摄像机角度捕获的图像形式展示。左侧图像显示了从合成生成（SG）输入开始的正视枫树重建。中间列的顶部行显示了从SG输入开始，棕榈树左侧摄像机视图的输入、重建和地面真实（GT）。同一列的中间行显示了从SG输入开始，樱桃树正视摄像机视图的输入。中间列的底部行显示了从SG输入开始的盆景树右侧摄像机视图的重建。最后，右侧列的图像显示了从SG输入开始的松树左侧摄像机视图的重建。


本文的主要贡献可总结如下：<br />1. 一种快速生成由随机控制的Weber-Penn参数开始的合成和真实3D树草图训练数据集的方法。<br />2. 一种具有多个输出的特定DNN架构，基于参数值集合以及训练和测试过程。<br />3. RT Blender附加组件和训练有素的DNN可在线获得，并可自由用于类似预测：[https://github.com/Unibas3D/TreeSketchNet](https://github.com/Unibas3D/TreeSketchNet)。

<a name="guafK"></a>
## 2 Related Work
在过去的几年中，对于重建具有非常复杂几何结构的对象（如树木），在3D中重建对象的最佳方式依赖于人类建模师的手动技能。随后，过程建模技术开始占据主导地位。该技术通过允许用户操纵参数系列的值来简化建模阶段，这些值与对象的几何形状相关联。然而，过程建模仍然需要用户进行培训阶段，以了解对象参数的工作方式。近年来，由于人工智能技术的快速发展，3D建模已经取得了新的突破，并变得更易于非专业建模师使用。在本节中，我们报道了在从草图或图像开始的3D网格生成领域的最新技术（SOTA）。

<a name="uZtMo"></a>
### 2.1 3D网格生成
使用新型传感器，如LiDAR或深度摄像头，对于拥有最新一代智能手机的任何人都非常熟悉。在此背景下，[24]提出了一种使用空中LiDAR数据和光学多视角航空图像自动重建3D屋顶的方法。[11]提出了一种使用单光子数据进行实时3D场景重建的计算框架。后者通过在白天从距离达到320米的地方获取LiDAR数据来重建复杂的户外场景。LiDAR扫描的点云也已被用于对真实世界的树进行建模，[10]提出了一种从空中LiDAR点云中以细粒度的细节模型化逼真树木的方法。该树模型首先通过分割单棵树点云，然后使用连接图最近邻搜索为每个点完成云的干扰点，进行重建。构建的分支骨架使用自底向上的贪婪算法发展，然后排列树叶。还有其他有趣的方法，使用扫描真实树木获得的树点云作为过程建模算法([25])或DNN([26])的输入来重建树木的逼真3D几何。许多其他研究使用深度摄像头传感器，例如[8]提出了一种仅使用一个深度摄像头和两个镜子进行3D重建的方法，而[27, 28]则使用Kinect深度摄像头进行3D重建。激光扫描是用于3D重建的另一种方法[12]。例如，[20]提出了一个自动化工作流，从移动激光扫描仪点云中检测树木并以单一树木建模结束。其目的是在3D城市模型中可视化单一树木。<br />[29]提出了一种通过结构和几何融合从现有树木自动创建3D树木的数据驱动机制。初始模型可以使用现有的3D建模工具或通过互联网仓库创建。[30]试图通过从RGB图像创建点云、纹理网格和带有皮肤的圆柱形关节刚体模型，以实现对树木进行几何和拓扑精确重建，以进行物理模拟。<br />与这些方法相比，我们不使用诸如激光扫描仪或LiDAR之类的专门设备来创建输入数据。实际上，这些仪器经常因与要扫描的真实对象相关的问题而受到影响，例如由于太阳角度过高或激光脉冲依赖于反射原理而导致的巨大反射。一个主要区别在于反映到我们系统的信息量。事实上，我们使用的是非常原始的数据（草图），其包含的信息比现有的多个RGB图像、点云或现有多边形网格少。<br />更一般地，正如[10]所指出的，3D树木建模技术可以分为过程式[31]、草图[32, 33]和基于图像[34, 35]的方法。<br />用于生成3D树木的方法[36]通常被概括为植物模拟和植被建模。[37]提出了一种捕捉植物燃烧过程的方法。他们的贡献之一是对100,000多个具有详细几何形状的个体植物进行野火模拟。类似地，[38]提出了一种模拟外候气候以根据温度、光照和水梯度模型树木生长的方法。植物生长模拟和可视化也是[39]所面临的问题，他们提出了一种基于语义分割的方法，允许对生长过程的获得的点云序列进行时间上采样，包括拓扑变化。<br />尽管这些方法在质量和正确性方面提供了令人印象深刻的结果，但其中一些是基于自组织过程生成一致的树木和植物[40]。与之不同，我们的工作考虑使用SG草图创建训练和验证数据集，并使用HM进行测试。

<a name="nDaQe"></a>
### 2.2 从图像到3D重建
使用RGB图像进行数字摄影测量是用于重建3D模型的最流行的技术之一。然而，诸如Reality Capture等软件工具要求获取大量图像以使用明确定义的方法[41]对单个真实对象进行3D重建。已有多项基于深度学习的研究试图从简单的单个RGB视图[13, 42, 43, 44, 45]开始生成3D对象。[46]提出了一种深度隐式表面网络，通过组合局部和全局图像特征以提高距离场预测的准确性，从而从2D图像生成3D网格。[47]提出了一种基于卷积解码器的体积式3D生成网络。后一种方法预测了八叉树结构，个别单元占用值提供了即使在有限内存的情况下也能提供高分辨率输出的能力。此外，它可以从单个图像生成形状，以及对象和整个场景的高级表示。使用深度学习生成点云的方法已被广泛探索。例如，[48]研究了基于点云表示的3D几何的生成网络。后一项工作的主要焦点是一个经过良好设计的流水线，用于从输入图像中推断出在3D框架中的点位置，考虑了视点。[49]提出了一种卷积递归自动编码器架构，以使用单个3D图像检索物体的长方体、连接和对称方面。编码器在形状轮廓估计任务上进行训练，解码器通过解析原始图像和网络，并递归解码长方体结构来关注结构特征。[50]研究了一种基于深度学习的方法，基于单个和多个视图重建体素3D表示。作者提出了一种基于编码器-解码器的框架，称为Pix2Vox，可用于从现实世界和合成图像中进行3D重建。<br />大多数基于图像和深度学习的3D重建方法涉及基于体素或点云的3D形状。它们仅限于重建简单而平滑的形状，如椅子、家具或汽车。<br />我们方法的主要差异在于要重建的对象，即树木，其具有更复杂和详细的微小结构，例如树枝和叶子。在这种情境下，直接预测3D树木模型要困难得多。此外，这些方法基于单个或多个RGB图像，相较于草图提供更多信息。<br />与我们类似，[51]使用了DNN来在3D中程序化地建模树木。实际上，他们使用了一种条件生成对抗网络（cGAN）来推导两个深度图像，这对于使用来自输入RGB图像的边缘和笔画来重建树木的轮廓和骨架作为3D点云是有用的。最后，他们使用基于自组织概念的过程建模方法从点云创建最终的3D树模型[36]。<br />尽管这种方法与我们的方法看似相似，但在方法论、输入处理和最终结果方面存在实质性差异。事实上，他们的输入包括使用[52]提取的树边缘的RGB图像和用户绘制的树骨架。这两个图像用于馈送cGAN并训练其创建先前提到的深度图像，将问题转化为图像到图像的转换任务。相反，我们直接使用草图馈送DNN并预测参数，无需进一步用户干预，保持使用的信息较少。通过这种方式，我们的方法更容易扩展到其他类型的草图和树种，并且可以在没有真实树木图片的情况下使用。

<a name="BBRd8"></a>
### 2.3 从草图到3D重建
正如[53]所报告的，使用草图来重建3D模型对于人类来说是直观的。在这个背景下，深度学习方法可以帮助使用最少的数据，如草图，生成3D网格。[54]提供了一个编码器-解码器架构，将2D草图转换为3D网格。该方法使用潜在参数来表示和细化可以匹配草图外部轮廓的3D网格。[55]提出了一种数据驱动学习方法，可以从一个或多个绘图中重建3D形状。这种基于卷积神经网络（CNN）的方法从线描中预测体素网格占用，并输出初始3D重建，而用户可以完成所需形状的绘制。无监督学习方法也用于3D对象建模。[56]提出了一种学习范式，用于从手绘（HM）草图重建3D对象，在训练过程中不依赖于标记的HM草图数据。他们的学习范式利用适应网络训练，尤其是自编码器和对抗性损失，并将成对的2D渲染图像和HM草图结合在共享的潜在向量空间中。在第二步中，从嵌入的潜在空间检索最近邻，然后使用训练集中的每个草图在3D生成对抗网络中使用。在[57]提出的一种不基于深度学习的有趣方法中，提出了一种通过勾画稀疏的2D笔画来对复杂的自由形状进行建模的工具。所提出的框架结合了多视图输入以建模一个可以被遮挡的复杂形状。与我们的方法相比，这些方法大多在与GT的一致性方面失败。事实上，他们的结果显示了即使对于简单的结构，如椅子和汽车，预测的网格也不平衡。此外，它们在树干和树枝等细长且分层的结构方面存在问题，而这方面没有显示测试示例。其中一些方法还需要用户持续介入以提高预测的准确性。相反，我们只使用单个草图作为我们管道的输入，而且对于需要重建的细长且分层的结构，预测是可靠的。
<a name="NKf4J"></a>
### 2.4 过程建模
基于规则的方法[58, 59]也可以利用深度学习，并且可以克服在规则集中操纵大量参数时对用户介入的需求。因此，[4]提出了一种HM草图方法，用于自动计算一组可用于生成类似于初始输入HM草图的2D/3D形状的程序模型参数。后一项研究的有趣之处在于它专注于三个程序建模规则集，即3D容器（例如花瓶）、3D珠宝和2D树木。由于任务的高复杂性，作者没有考虑3D树木形状的生成。然而，通过控制程序建模算法的输出，一些其他方法可以克服这个问题。这些方法包括[60]，它使用基于遗传的算法，以及[31, 61]，它基于马尔可夫链的蒙特卡洛。与我们的方法不同，这些方法需要用户进行参数学习阶段，以了解它们的功能。为了进一步简化建模师的工作，[62]开发了一款基于程序建模的应用程序，用于使用平板生成3D树模型。建模师可以使用笔刷定义树的轮廓和分支生长的方向。树的许多其他细节需要通过操作与程序建模算法相关的参数来定义。尽管这种方法比之前的方法更直观，但参数的存在意味着用户需要进行先期研究，而这在我们的方法中是不必要的。<br />重要的基于规则的方法是L系统，由[63]提出，广泛用于植物生成。事实上，[64, 65, 26]提出了基于L系统模型的多种算法。特别是，[66]引入了一种有趣的反向程序建模方法，该方法使用深度学习从具有分枝结构的输入图像中检测L系统。显然，由于这种方法只能预测用于生成线性分支结构的参数，因此输入图像和生成的语法都没有有关树冠的信息。[67]提供了一种可以克服此限制的方法。他们使用了基于三个DNN的深度学习的组合，这三个DNN从树的输入照片开始，掩蔽树，识别树种，并提取树的径向包围体积（RBV），分别。然后，RBV用作生成树的3D模型的程序化建模算法的输入。因此，可以看出，这种神经架构比我们的复杂得多。此外，他们的输入RGB图像比草图包含更多的3D提示，如阴影和关于纹理的信息。从HM草图生成3D模型的新方法也很有趣。[17]使用多编码器-解码器网络架构从单个草图创建最终的覆盖3D服装。网络体系结构的复杂性与需要预测不仅是2D服装图案参数，还有与之相关的身体形状参数有很强的联系，以获得最终与输入草图相似的3D服装。[68]遵循使用多个神经网络来预测不同参数集的思想。实际上，他们使用两个神经网络来预测来自输入模特草图的2D轮廓和2D关节。然后，这些中间表示被用来生成模特的3D模型。与前两种方法不同，我们的方法能够使用单个神经网络生成3D树模型，而无需使用中间表示，尽管树的几何形状与复杂且非线性的规则集相关。

<a name="AiOLA"></a>
## 3 3D树参数的生成
在本节中，我们讨论我们的方法的详细信息，特别是：(i) 数据集创建管道；(ii) TSN 的配置；和 (iii) 训练过程。RT Blender 插件是我们管道中的关键元素，因为它能够快速生成训练数据集并可视化3D树网格。后者是从TSN使用由该插件创建的SG草图预测的Weber-Penn [1]参数生成的。为了定义我们的参数，我们采用了CG植被模拟中当前标准的符号，如[31, 69, 70, 71]中所用。

<a name="K04HH"></a>
### 3.1 数据集创建管道
受监督学习方法的一个弱点是找到一种安排大量标记数据的方式，这些数据还必须结构良好，以获得期望的结果[72, 73, 74]。我们的RT Blender 插件通过为每个树种创建250个3D树网格并将参数存储在每个树的专用字典文件中（请参阅我们的 GitHub 网站[75]上的详细信息）来克服这个缺点。我们将Weber-Penn参数分为两个子集：固定和非固定。固定参数对于相同的树种采用相同的值，而非固定参数采用随机控制的值，变化树的形状和详细的视觉特征。TSN可以通过添加一个分类分支来学习识别输入草图中显示的树种。然而，这会增加其复杂性，并因此降低预测性能。此外，添加分类分支是不必要的，因为可以使用固定参数来识别与输入草图相关联的树种。这个任务被实现为一个强大的算法1，将在第4节中讨论。从现有的Sapling Tree Generator Blender插件开始，我们手动为5种树的每一种定义了一个固定和非固定参数的字典。这里的目标是获得在视觉特征方面一致的3D树网格。选择这些树种是为了尽可能引入与其形状和视觉特征相关的差异。我们的RT插件生成的一致网格字典被用作生成其他3D网格和它们各自的参数字典的起点。非固定参数相对于它们的数量级进行了随机变化，如表1所示。通过这种方式，我们为每种树获得250个字典，这些字典分别用于我们的RT插件生成相应的Blender Curve [76]对象。该对象转换为两个网格：树的骨架（主干和分支），不包括叶子，以及仅叶子。<br />获得的网格加载到与4个相机对应的精心设计的Blender场景中，这4个相机分别对应于树的4个视图：前视图、后视图、左视图和右视图，如图2所示。选择这些视图是因为它们易于识别，并且还可以更容易地与TSN预测的3D模型进行视觉比较。此外，4个视图中的每一个都完全不同于其他视图：这个特征可以减少TSN的过拟合，从而提供很高的泛化水平，如图7所示。我们还尝试过用其他视图训练我们的TSN，但没有显着改善。此外，我们的场景包含一个定向光源，没有阴影，以更好地照亮树木。全局场景照明包括Blender路径跟踪和环境遮蔽，以增加渲染的真实感。设置场景后，必须渲染每个视图的SG草图。SG草图生成管道的第一步是向树添加两种黑色材质，一种用于主干，一种用于叶子，如图2a和2b所示。第一种是一个具有零粗糙度的简单漫反射材质。第二种包含一种简单的叶形黑色纹理，基于树种。

Table 1: 未固定参数及其范围（最小值和最大值）。Sign参数是二进制的。

| Unfixed Parameters | Min Values | Max Values |
| --- | --- | --- |
| Sign (binary) | -1 | 1 |
| Tree Forks Number | 0  | fixed parameter |
| Parent Branch Roll Angle | -360 | 360 |
| First Half Internodes Branching Angle | -360 | 360 |
| Second Half Internodes Branching Angle | -360 | 360 |
| Internode Branching Angle Variance | -360 | 360 |
| Sibling Angle | -360 | 360 |
| Sibling Angle Variance | -360 | 360 |
| Branch Roll Angle | -360 | 360 |
| Branch Roll Angle Variance | -360 | 360 |
| Leaf Roll Angle | -360 | 360 |
| Leaf Angle Variance | -360 | 360 |
| Leaf Scaling Factor | 0 | ∞ |
| Leaf Scaling Factor Variance | 0 | 1 |
| Parent Branch Angle Variance | -360 | 360 |
| Number of Branch Whorls | 0 | ∞ |

翻译：

| 未固定参数 | 最小值 | 最大值 |
| --- | --- | --- |
| Sign（二进制） | -1 | 1 |
| Tree Forks Number（树的分支数） | 0 | fixed parameter |
| Parent Branch Roll Angle（父分支滚动角） | -360 | 360 |
| First Half Internodes Branching Angle（前一半分枝角度） | -360 | 360 |
| Second Half Internodes Branching Angle（后一半分枝角度） | -360 | 360 |
| Internode Branching Angle Variance（分枝角度方差） | -360 | 360 |
| Sibling Angle（兄弟分支角度） | -360 | 360 |
| Sibling Angle Variance（兄弟分支角度方差） | -360 | 360 |
| Branch Roll Angle（分支滚动角） | -360 | 360 |
| Branch Roll Angle Variance（分支滚动角度方差） | -360 | 360 |
| Leaf Roll Angle（叶片滚动角） | -360 | 360 |
| Leaf Angle Variance（叶片角度方差） | -360 | 360 |
| Leaf Scaling Factor（叶片缩放因子） | 0 | ∞ |
| Leaf Scaling Factor Variance（叶片缩放因子方差） | 0 | 1 |
| Parent Branch Angle Variance（父分支角度方差） | -360 | 360 |
| Number of Branch Whorls（分支螺旋数） | 0 | ∞ |


![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1704345465824-838d3f51-345a-478a-b5d4-ce77ec2acfaa.png#averageHue=%23efefee&clientId=uc6ee5aa7-2d91-4&from=paste&height=181&id=u8c80c695&originHeight=226&originWidth=800&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=113233&status=done&style=none&taskId=ue064b4d4-463d-4ac6-9c5e-3eab34f9a9a&title=&width=640)
> Figure 2: 生成SG草图的过程。对于每个相机视图，树的骨架和叶片在应用黑白材质并经过一系列特定于两种类型网格的预处理操作后分别渲染。在最后一步，这些渲染结果混合在一起以获得最终的SG草图。


接下来的步骤是使用先前定义的黑色材质分别渲染树的骨架和叶子网格。为了获得骨架边缘，我们定义了几个步骤，如图2c所示：(i) 第一步是轻微地缩小骨架网格，以去除最细的分支；(ii) 第二步包括以下一系列合成操作[77]：<br />(a) 使用0.5阈值删除背景；<br />(b) 应用基于Intel® Open Image Denoise的滤波器以删除残留的背景伪影；<br />(c) 应用Sobel滤波器[78]来追踪粗略的轮廓；<br />(d) 应用颜色渐变，将像素值小于0.9的设置为0，其余设置为1，以突出所有分支边缘；<br />(e) 应用反转颜色滤镜以获得负片，带有白色背景和黑色边缘；<br />(f) 应用侵蚀形态学运算以删除散点并生成最终的骨架草图，如图2c所示。

类似地，为了获得叶子边缘（见图2d），我们使用了一个更简单的合成操作链，包括：<br />(a) 使用0.9阈值应用背景去除滤镜；<br />(b) 应用强烈的高斯滤波器来均匀化和强调叶子的形状；<br />(c) 应用颜色渐变，将小于0.01的值设置为0像素，其余设置为1，以包括模糊的叶子边缘；<br />(d) 应用Sobel滤波器来追踪边缘；<br />(e) 应用与骨架草图相同的反转颜色滤镜以获得叶子草图，如图2d所示。

最终的合成草图是通过将骨架和叶子图像相乘获得的（混合草图），如图2e所示。为SG草图选择的绘图风格旨在类似于Typical用户手绘的手绘草图，如[79, 80]所示。<br />对于场景中的每个相机视图，我们生成一个SG草图。因此，最终数据集包括250棵树 × 4视图 × 5树种 = 5000棵树的SG草图（每种树1000幅草图[51]），以及它们的参数字典和地面真值（GT）图像。分辨率为608 × 608，这是我们测试的核心网络支持的最大维度（见第5.2节）。此初始分辨率可以根据每个测试的TSN所需的输入进行调整，包括我们选择的TSN（见第3.2节）。数据集被分为训练集和验证集，其中包括5种树的示例，以及它们的GT参数和SG草图，如图3所示。验证集包括每个树种的单个视角，而训练集包括其他三个视角[81]。一个特定的测试数据集是单独创建的，如第4节所述。

<a name="uy7Qh"></a>
### 3.2 TSN体系结构和训练过程
为解决回归问题，我们定义了一个基于EfficientNet-B7的专用TSN体系结构作为核心网络。在一系列与其他著名网络的实证实验中，EfficientNet-B7被发现是我们体系结构的最佳核心网络，如第5.2节所述。EfficientNet-B7属于一系列网络，从初始网络架构EfficientNet-B0开始创建，随后通过[82]提出的方法进行均匀扩展，该方法旨在通过等比例扩展EfficientNet-B0的宽度、深度和图像分辨率来提高性能。所有EfficientNet架构都由一个卷积层后跟7个宏块组成，每个宏块包含Li反转残差块，有时称为MBConv块[83]。EfficientNet-B7在ImageNet上比现有CNN更小8.4倍、更快6.1倍，并且准确性更高。<br />我们的TSN输入由224 × 224的重塑草图组成（见3.1节）。这是因为训练CNN的图像分辨率通常在64 × 64到256 × 256之间，考虑到CNN模型在较低的输入图像分辨率下性能更好[84]。此外，[82]显示EfficientNet基础模型的准确性增益在达到80%后饱和，即使对于高于224 × 224的分辨率。每个草图没有α通道，以保持与用于训练和测试EfficientNet的数据集中的图像一致[82]。每个草图的背景是白色的，以使TSN更有效地提取图像的基本特征[85]。由于我们使用监督学习范 paradigm，每个输入图像都与相应的树参数关联，结构化为我们称之为目标矩阵的矩阵。目标矩阵的每一行表示一个单一的参数，列值为参数值。由于每个参数项的值的数量可以是4或1，我们的目标矩阵的维度为4 × np，其中np = 62是参数的数量（见我们GitHub网站的详细信息[75]）。为了生成一致的矩阵，1值参数在每一列中重复。该矩阵包含在我们GitHub网站[75]中报告的所有固定和未固定参数，而不考虑剪枝、装甲和动画参数，这些参数在强制的位置上保留为默认值。为了避免过度拟合和拟合不足问题（见3.2.1节），基于它们的数量级，我们将该目标矩阵划分为六个子矩阵，分别表示每个最终TSN分支的目标。每个子矩阵的维度为4 × nt，其中nt ∈ [1; np]，表示特定数量级的参数数量（详见3.2.1节的详细信息）。我们的TSN使用Adam [86]进行训练，初始学习率为1e<br />−5，并使用均方误差作为损失函数。在训练阶段，我们使用(1 − RMSE) ∗ 100（均方根误差）来评估性能准确性。由于训练数据集不是很大，我们使用了在ImageNet [87, 88]图像数据集上使用的EfficientNet-B7层的预训练模型。这种技术被广泛用于在没有很大数据集的情况下获得良好的网络性能[89]。我们进行了一些测试以选择最佳的批处理大小值，对于我们的方法，批处理大小等于8。我们的TSN是使用NVIDIA Titan XP GPU进行训练的，具有12 GB G5X帧缓冲区。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1704346175232-839cd293-534a-443a-9fb5-b094061829d5.png#averageHue=%23fcfbfa&clientId=uc6ee5aa7-2d91-4&from=paste&height=394&id=u04668849&originHeight=492&originWidth=836&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=50645&status=done&style=none&taskId=u10c0a6ca-a2a7-4bc4-ac40-7397054301d&title=&width=668.8)
> 图中显示了我们TSN的架构，输入为224 × 224的草图。初始块是一个简单的卷积层。接下来的块包含Li MBConv块。网络的最后一部分由六个分支组成，每个分支对应一个参数数量级。每个分支都有一个具有线性激活函数的全连接层和一个重塑层。

<a name="AhPrq"></a>
#### 3.2.1 过拟合和欠拟合
在几次尝试后，我们确定了最佳数据集和TSN配置，解决了过拟合和欠拟合的问题。我们的第一种“玩具”方法使用了基本的VGG-16 [90]深度神经网络作为核心网络，表示为608 × 608的渲染（草图和GT）图像。发现这种配置导致了一般性的过拟合，其中一些分支的过拟合程度较高，损失也很大。因此，在每个受过拟合影响较小的分支之前插入了dropout层[91]，对于受过拟合影响较大的分支，α = 0.2，对于受过拟合影响较大的分支，α = 0.5。训练期间的高损失可能是梯度消失问题的指示，因此也可能是欠拟合的问题。为了减少这个问题，我们采用了具有skip连接的残差学习方法[95]，这些连接被放置在VGG-16核心网络的连续层之间。尽管后一种方法表现得相当好，但我们将其作为最终配置的基准。这种配置使用了更近期的EfficientNet版本，能够更好地处理上述问题。另外四次尝试使用ResNet [95]（变体50），AlexNet [96]，Inception V3 [97]和CoAtNet [98]作为核心网络。ResNet和Inception V3是许多计算机视觉任务中使用的经典神经网络[99]，AlexNet在类似的草图到网格参数方法的可比研究中被使用[4]，而CoAtNet和EfficientNet则代表了图像识别的SOTA。第5.2节报告了VGG-16与skip连接和EfficientNet-B7之间的定量性能比较。使用VGG-16作为核心网络，我们尝试将整个目标矩阵作为DNN的输出，只有一个输出分支。然而，结果非常差，DNN完全欠拟合。因此，我们定义了6个DNN输出分支，基于参数值的数量级。这是因为Weber-Penn Blender参数字典包含异构数据，如我们在GitHub网站[75]中报道的。因此，我们能够根据它们的数量级进行转换和调整许多参数。具体而言，我们为每个DNN输出分支定义了几个子矩阵，如图4所示。将离散整数和字符串参数值解析为浮点数；将布尔参数值解析为整数；使用标签编码方法将非数值字符串参数值解析为浮点数（例如，在我们的GitHub网站[75]中描述的Leaf Shape）；将二进制[−1；1]参数转换为[0；1]。尽管考虑[− inf, inf]值是不可能的，但我们对它们进行了标准化，并使用Max Abs Scaling方法将[−360, 360]值标准化到[−1, 1]范围内。这样可以缩放数据并保留稀疏性。最大值被存储在归一化矩阵中，并在测试步骤中被重复使用。对Inception V3的测试确定了在[− inf, + inf]和[0, 1]的DNN输出分支上存在显著的过拟合，通过在前两个全连接层上添加L2正则化[100]，然后使用α = 0.2的dropout层来减少这一问题。我们在[−360, 360]的DNN输出分支上得到了一点过拟合；在这种情况下，我们只使用了α = 0.5的dropout层来减少问题（见图4）。EfficientNet-B7在每个分支上都表现良好，对[0, ∞]，[−1, 1]，[−360, 360]和[min, max]分支的性能稍微更好。为了简单起见，图5显示了通过对各个分支的损失进行平均计算的TSN的总体训练和验证损失。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706691559661-26c3a93a-fe2a-4621-886b-948b94d099af.png#averageHue=%23fbf8f8&clientId=u09922142-6bf1-4&from=paste&height=154&id=u96dc6f05&originHeight=192&originWidth=439&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=18117&status=done&style=none&taskId=u7db0155a-9171-49a4-9a1f-7a410fef20d&title=&width=351.2)
> 图5：TSN的训练损失与验证损失。

<a name="tfUOQ"></a>
## 4 结果
树的草图是我们TSN的输入，该网络生成包含预测参数值的六个4 × nt子矩阵（见第3.2节）。这些子矩阵需要进行反标准化，然后与它们在训练阶段后存储的相应归一化矩阵相乘。这个操作使得可以将预测的TSN值作为有效的Blender输入。从单个草图预测获得的子矩阵被重新排列为类似Blender的参数字典。特别是，每个子矩阵列与一个字典键相关联，表示一个特定的参数。当期望的参数不是由四个元素的向量而是由单个值表示时，仅取第一个值。该字典还用于识别预测树的物种（参见算法1），并根据树的物种从相同的字典为3D Blender网格分配正确的纹理。具体而言，算法1接受两个数据结构作为输入。第一个是一个精心设计的基于字典的数据结构，其中包含为每个树物种组织的特征参数CP。 cp ∈ CP中的每个元素都包含三项信息：参数名称，其值和树物种。如果参数满足两个属性：（i）它总是存在于该特定树物种的所有样本中; （ii）其值在该树物种的特定范围内，那么就为该特定树物种定义一个参数cp。第二个输入是P，这是一个包含预测参数的字典。我们将每个p ∈ P与每个树物种的相应cp进行比较，使用参数名称，并验证p的值是否满足以下条件：<br />p.value ∈ [cp.value − ε, cp.value + ε]（1）<br />其中[cp.value − ε, cp.value + ε]是该树物种的可接受值范围。让eligible是一个字典，其中键是树的物种，值是计数器（每个树物种一个）。如果预测的参数满足条件（1），那么该参数对该树物种是符合条件的，其计数器会增加一。最后，算法1根据计数器的最高百分比返回预测字典的树物种。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706691822651-0a6f3a83-5bd2-4ed6-a6c6-0022cfeb6cb5.png#averageHue=%23f8f7f5&clientId=u09922142-6bf1-4&from=paste&height=216&id=u96e690df&originHeight=270&originWidth=831&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=51455&status=done&style=none&taskId=u96040e31-89fe-4cca-a5ba-83223f20ff4&title=&width=664.8)然后，重新排列的预测参数字典从Blender中加载，并使用我们RT插件中的加载实用方法进行解释。该实用程序可以根据输入字典生成3D树网格，并根据算法1检测到的树物种分配正确的纹理。纹理是从每个树物种的预定义纹理集中选择的。为了测试我们的方法，基于我们的树物种定义了一个合适的数据集。图6显示了与我们的RT插件生成的训练集相似的输入SG草图，重建的3D树网格和GT。正如图6所示，我们的TSN正确预测了测试草图的树结构，特别是关于每个树干段的分裂数量，曲线角度，分支数量和分布，树干与其高度的比例以及总体高度等方面。正如图6所示，我们的结果在视觉上与输入草图一致，并且在SG草图方面与GT参数一致。为了展示TSN的泛化能力，我们还创建了一个包含以不同视角渲染的草图图像的测试集，相对于用于生成训练数据的4个视角。在图7中显示了这个测试的结果，证实了TSN的泛化能力。图8展示了一些SG草图以及根据预测的参数字典在Blender中生成的3D网格。图8还显示了根据树物种应用的材料，以及每个3D网格的法线映射。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706691898060-a6ab3cc9-fc35-4c36-8b95-fab89a2d555f.png#averageHue=%23d7d2cf&clientId=u09922142-6bf1-4&from=paste&height=258&id=uce5343d9&originHeight=323&originWidth=787&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=291260&status=done&style=none&taskId=ua2c4be7f-29d8-4e85-9924-4f2de08de0a&title=&width=629.6)<br />图6：从相同的相机视角获取的来自我们RT插件的SG测试集的结果，针对每个树物种。第一行显示了输入的SG草图；第二行显示了使用相应的预测参数字典重建的3D网格；最后一行显示了GT。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706691906510-d7f2c6c2-cefb-438a-94a1-cf86f8489f58.png#averageHue=%23ecebea&clientId=u09922142-6bf1-4&from=paste&height=317&id=u42f1afdc&originHeight=396&originWidth=817&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=170058&status=done&style=none&taskId=u5e2c4b7d-a5ca-4018-997d-73b173834da&title=&width=653.6)<br />图7：TSN网络对给定具有不同相机视角的图像的结果：在左列，相机向右倾斜；在中间，相机底部放置且向上倾斜；在最后一列，相机向左倾斜。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706691917470-710c51e3-4665-4bf0-9f7a-edaa568e1143.png#averageHue=%23ecebeb&clientId=u09922142-6bf1-4&from=paste&height=281&id=u9d58c68e&originHeight=351&originWidth=855&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=181193&status=done&style=none&taskId=u6c067d0d-2b2c-4b6c-865f-2180e72c78a&title=&width=684)<br />图8：该图显示了一些测试草图的示例，以及相应的GT和预测。骨架显示树干和分支正确符合起始草图。在“Material”列中报告的重建的树表明了叶片与输入草图中提出的形状之间的对应关系。最后一列显示了没有任何材料的简单重建网格。

<a name="V2hqU"></a>
## 5 比较
据我们所知，这种方法是首次尝试从明确定义的预测参数生成3D树形状。因此，我们尽力将我们的结果与其他方法进行比较。受[4]的启发，我们基于由15名不同用户提供的HM草图进行了用户研究，如第5.1节所述进行了评估和验证。此外，我们使用不同的核心网络进行定量比较，以验证我们选择EfficientNet-B7作为最佳选择（见第5.2节和第5.3节）。最后，我们提供了对TSN预测参数的广泛定性分析，如第5.4节所述。
<a name="zM7J8"></a>
### 5.1 受控实验
为了在实际环境中测试我们的方法，我们进行了一项包括15名非专业绘画者的受控实验。每个人被要求为每个树物种提供一张草图。目标是评估TSN对参与者提供的HM草图进行参数预测的置信水平。参与者可以选择任何软件包来绘制他们的树。对于每个参与者，我们随机选择了5张SG草图，每个树物种一张。要求参与者观看每个SG草图两分钟，然后按照自己的风格绘制树的草图。通过这种方式，参与者可以了解系统能够处理哪些树种，而不受绘图方面的太多限制。<br />为了对TSN的泛化能力进行另一个显著的证明，我们采用了[17]的方法，该方法在给定HM草图的情况下，通过使用TSN草图的特征从训练集中找到SG草图的最近邻草图（NNS）。图9显示了HM草图、上述重建的SG草图和NNS之间比较的结果。图9的第一列显示，重建的SG与HM草图更相似，而不是NNS。这可以从树干的宽度（绿框）以及NNS中存在的额外分支（蓝框），而在HM草图和重建的SG中不存在，可以注意到。第二列显示了与HM和SG重建草图相比，具有不同方向和树干弯曲的NNS。此外，在NNS中，我们可以计数左侧和右侧的分支（绿框）少了一个，而在HM和SG重建的草图中没有。蓝框标志了树的顶部。在第三列中，可以注意到NNS与HM草图相当不同。相比之下，重建的SG草图在树干的形状（蓝框）以及弯曲（绿框）和分支的一般排列方面更像HM草图。在第四列中，HM草图和SG重建的草图之间的弯曲和分支的一般排列（蓝框）更类似于HM草图和NNS之间。在最后一列中，NNS相比重建的SG和HM草图具有额外的分支卷。此外，HM草图的一般分支排列更类似于重建的SG草图而不是NNS。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692101329-1aeeaf49-b17f-4bbd-8c31-b3e0fece4d05.png#averageHue=%23e3e2e2&clientId=u09922142-6bf1-4&from=paste&height=466&id=u9f5e6b32&originHeight=583&originWidth=763&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=284216&status=done&style=none&taskId=u6dfff942-89f7-4ebd-a950-f826afe874e&title=&width=610.4)<br />图9：TSN的泛化能力。第一行显示HM草图。第二行显示TSN从HM草图生成的3D模型。第三行包含从重建的3D模型获得的SG草图。最后一行显示从训练集中检索的最近草图。

<a name="RJ3BI"></a>
### 5.2 核心网络测试
核心模型的选择可以极大地影响方法的结果。因此，我们对不同的核心模型进行了测试，并评估了它们的性能。特别是对于每个测试的核心模型，我们分析了每个特定分支的1 − RMSE，以及所有分支的整体平均值。第一个比较是EfficientNet-B7和具有skip连接的VGG-16之间的比较（见第3.2.1节）。第二个比较是使用ResNet和Inception V3进行的，它们在许多计算机视觉任务中用作核心模型[97]。对于ResNet，我们使用了变体50，因为其深度足以提取我们任务所需的基本低级特征。对于使用Inception V3进行的测试，我们使用了前2个卷积块和前5个Inception模块，以减少DNN的复杂性，从而减少由于过度参数化而引起的过拟合问题[101]。我们还将EfficientNet-B7与AlexNet [96]进行了比较，以评估在[4]中提出的基于程序建模的方法在3D网格生成中的有效性。为了完整起见，我们最后将EfficientNet-B7与另一个SOTA网络CoAtNet进行了比较。每个测试都使用了30个草图，其中包括15个SG草图和15个HM草图。对于每个核心模型，我们对我们的架构进行了2k个epoch的训练，评估基于以下因素：（i）根据验证曲线准确性与训练曲线准确性的比较，分支（低和高）可能的过拟合；（ii）每个分支的准确性，通过观察验证曲线进行评估；以及（iii）通过观察测试曲线进行的泛化水平。<br />表2显示了与基于SG的测试集的比较结果。这些草图是使用我们的流水线获得的，如第3.1节所述。SG测试使用了所有参数，并将预测字典与GT参数进行了比较，使用1−RMSE。相对于其他核心模型，EfficientNet-B7表现更好。然而，CoAtNet在[−360, 360]分支上的表现略好于其他模型。Inception V3的表现也不错，但没有分支能超越EfficientNet-B7。总体性能表明EfficientNet-B7优于其他网络。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692131473-f446dfc5-0ab0-4bec-a321-874968b4bce3.png#averageHue=%23f4f1ee&clientId=u09922142-6bf1-4&from=paste&height=146&id=PzFdi&originHeight=182&originWidth=774&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=56666&status=done&style=none&taskId=u52297576-883a-4e43-9404-4575c0c1629&title=&width=619.2)<br />表2：SG草图的核心网络比较。总体1−RMSE的观察表明EfficientNet-B7具有更高的准确性。然而，在[−360, 360]分支上，CoAtNet的表现略好于其他模型。最佳值以粗体突出显示。<br />对于HM测试，我们准备了一些手工制作的草图，灵感来自于由SG生成的草图（见第3.1节和图2），并将它们的相应参数视为GT。表3中的比较显示，对于HM草图，与其他三个核心模型相比，两个SOTA网络（Efficientnet-B7和CoAtNet）以及Inception V3均取得了更好的结果，表现出更高的泛化水平。特别是，我们可以注意到EfficientNet-B7相对于CoAtNet和Inception V3具有更高的准确性。此外，对比表2和表3中的结果，这两者具有相似的特征，并对训练报告进行分析，发现AlexNet在[0，inf]和[min，max]上略有过拟合。通过将同样的分析应用于其他核心模型，我们发现对于带有跳跃连接的VGG-16，分支[−inf，inf]和[0，inf]略有过拟合，而对于ResNet-50、Inception V3、EfficientNet和CoAtNet则没有过拟合的迹象。然而，由于EfficientNet-B7相对于其他DNN具有更高的准确性以及其对与训练数据显著不同的HM草图的泛化能力，因此被选择为最佳核心模型。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692276840-b7c34262-3c09-4a78-9c71-7696b0e37276.png#averageHue=%23f5f2ef&clientId=u09922142-6bf1-4&from=paste&height=150&id=u7b6526af&originHeight=187&originWidth=786&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=57667&status=done&style=none&taskId=u2f15d240-356d-4078-9261-c20dc431c35&title=&width=628.8)表3：HM草图的结果清楚地显示了不同核心网络之间的差异。基于总体性能，EfficientNet-B7具有更高的准确性。尽管手绘草图之间存在差异，EfficientNet-B7被证明具有更强的泛化能力。最佳值以粗体突出显示。
<a name="hJoJo"></a>
### 5.3 侯斯多夫距离
由于在前面的部分中，我们提供了对DNN性能的准确性的定量分析，因此在本节中，我们评估了重建的3D树的质量。为此，我们使用了一种称为侯斯多夫距离（HDD）[102]的度量标准。特别是，我们比较了EfficientNet-B7、CoatNet和Inception V3的距离，因为它们代表了性能最佳的DNN，如前面的部分所报道。HDD表示两个网格之间一组距离中的最大距离。该集合包含第一个和第二个网格的顶点之间的所有最小距离。在我们的情况下，对于每个DNN，我们计算从DNN预测重建的15棵不同物种的树的网格与它们的地面真实网格之间的HDD。这15棵地面真实树对于所有DNN都是相同的，以确保结果的一致性。表4显示了每个网络计算得到的HDD的平均值。从表4的结果可以看出，EfficientNet-B7仍然是更好的选择，因为它的HDD更趋近于0。这意味着EfficientNet-B7生成的网格与其地面真实相比更相似，而不是由Inception V3或CoAtNet生成的。此外，我们的方法在计算此度量时提供了比SOTA [51]更好的结果。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692329587-b0c837fe-6a71-49a3-a867-196255f3e7db.png#averageHue=%23f9f8f7&clientId=u09922142-6bf1-4&from=paste&height=82&id=uecf51577&originHeight=103&originWidth=787&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=15860&status=done&style=none&taskId=ubccebe58-b4af-43a3-8151-575e45807f9&title=&width=629.6)表4：性能最佳的DNN的侯斯多夫距离。根据结果，EfficientNet-B7生成的网格与其地面真实更相似。最佳值以粗体突出显示。

为了进一步测试TSN的准确性，我们提供了一个实验。它包括生成TSN从未见过的树的3D模型，并将其旋转5度，直到达到起始位置。对于每次旋转，必须渲染一个新的SG草图，并将其作为输入提供给TSN。最后，必须为每个TSN预测计算HDD。如图10所示，对于每个旋转度数，HDD值约为0.03，与表4中的结果一致。图11呈现了实验的最坏、中位和更好情况。每列包含作为输入提供给我们TSN的SG草图，由TSN预测的3D模型，带有逼真纹理的地面真实的3D模型，以及其顶点具有与其HDD值相对应的颜色的地面真实的3D模型。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692455327-782847de-774f-4a63-9e83-54b525bbb9d9.png#averageHue=%23fcfaf7&clientId=u09922142-6bf1-4&from=paste&height=151&id=u9ea5b2ef&originHeight=189&originWidth=755&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=23491&status=done&style=none&taskId=uf6e36eca-ab1b-42d6-bdc5-e6ac84fe7fb&title=&width=604)<br />图10：每个旋转度数的HDD距离。由于HDD值接近0，我们将y轴范围缩小为[0, 0.1]。通过这种方式，突出显示了树之间的最小差异。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692562596-155f9175-5f43-4160-9c9e-7bc6bbe3f9fb.png#averageHue=%23e7e3e1&clientId=u09922142-6bf1-4&from=paste&height=379&id=ue6affe14&originHeight=474&originWidth=803&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=284847&status=done&style=none&taskId=u101f6224-60aa-4850-ac92-f984c0c416e&title=&width=642.4)<br />Figure 11: 实验的最差、中位和最好情况，采用不同旋转度数。每种情况下都呈现了SG输入草图、重建的3D模型，以及地面真实的3D模型，其中包含逼真的纹理（Ground Truth）以及其顶点具有与HDD值相对应的颜色（GT HDD）。在图的底部，显示了HDD均值。
<a name="EfG1t"></a>
### 5.4 定性分析
在本节中，我们通过使用GT参数未知的HM草图，对我们TSN的预测参数进行了经验分析。为此，我们根据输入草图手动提取了每个树种的一些易于看到的参数，并将其与TSN的预测进行了比较。表5描述了本节采用的符号。<br />图12显示了输入的HM枫树草图以及一些简单的视觉参数。这个表格展示了一些TSN的预测参数和性能准确性。特别是，第一个GBS值（深橙色高亮显示）显示树干（第一级分支）向上吸引（正号），而树枝（第二级分支）向下吸引（负号），并且有不同的吸引系数，这些都是我们TSN正确预测的。树干高度表示枫树高度的约30%没有分支。草图中的树干也分为两部分，由预测的NT F参数（绿色高亮显示）确认，该参数指示一个树干细分。NB参数指示每个分支级别的分支数量。在枫树的情况下，第一级别的分支数为0，因为树干不被视为分支，而第二级别的分支数为54。φF IB和φSIB树干符号为正，这意味着树干及其顶端向树的前方弯曲。第二级分支及其顶端向与树干相反的方向弯曲，如相关草图所示。其余的参数也都被我们的TSN正确预测，特别是，例如NL参数表明该草图具有两个分支级别。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692707206-1c610065-a4f1-4a5b-a5fd-007dbc8a3a45.png#averageHue=%23f6f4f3&clientId=u09922142-6bf1-4&from=paste&height=273&id=uf13eeb7f&originHeight=341&originWidth=776&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=87989&status=done&style=none&taskId=u9a8153ae-355e-4064-ae2f-b0889877b97&title=&width=620.8)<br />Figure 12: 枫树的简单视觉参数。相应的表格报告了TSN的预测值。数组结构参数中元素的索引表示分支级别。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692713759-2472caf8-9216-49e2-a332-d2018a533c4a.png#averageHue=%23faf8f7&clientId=u09922142-6bf1-4&from=paste&height=258&id=u71f196e6&originHeight=322&originWidth=778&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=68752&status=done&style=none&taskId=u1d3eb1df-e88b-40df-bb4c-8ac37894821&title=&width=622.4)<br />Figure 13: 棕榈树SG草图的示例，带有预测的参数。预测的准确性主要通过BD和CBH参数来证明，这些参数表明叶子集中在树的顶部。<br />图13是一些简单参数及其对应的TSN预测值的视觉比较。在这种情况下，CBH指示棕榈树只有1%没有分支，但BD参数将所有分支汇集到树的顶部，并减弱CBH的影响。这一方面也在图12中的枫树示例中得到了确认，其中这两个参数是平衡的。草图中，树干没有细分，由NT F参数指示。由于φF IB和φSIB树干符号不一致，树干呈S形，并向后弯曲（φF IB为正号），其顶端（φSIB为负号）向前弯曲。第一级分支沿着树干的曲线走向。最后，这个示例展示了NBW参数，指示分支在树干周围分布的环数。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692720641-a02fbdab-894b-437e-b45b-7eeff68ff61f.png#averageHue=%23f8f6f5&clientId=u09922142-6bf1-4&from=paste&height=235&id=ub9f4a888&originHeight=294&originWidth=778&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=83606&status=done&style=none&taskId=u77044d98-df2f-4569-a432-49109c10e24&title=&width=622.4)<br />Figure 14: 该图和相应的表格显示了我们系统对N_BW数量的正确预测，以及其他参数。<br />图14中最明显的参数是NBW，对应的表格特别显示了GBS、φF IB和φSIB参数的符号和数量。红色箭头显示了φF IB参数的符号，表明所有分支级别都向前弯曲。最后两个分支级别的顶端曲率与它们的基底相同的曲线方向，而树干顶端相对于其基底弯曲向后，如φSIB参数所示。在这种情况下，所有级别的分支都向上吸引，正如我们的TSN正确预测的那样。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692727456-01b1bdd7-e5b0-498b-b86d-091b54bb9857.png#averageHue=%23f5f3f2&clientId=u09922142-6bf1-4&from=paste&height=231&id=ufb8011b0&originHeight=289&originWidth=768&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=80436&status=done&style=none&taskId=u9c203433-09a6-4a8d-b34c-ae2d1dd55d9&title=&width=614.4)<br />Figure 15: 樱桃树的示例。在这种情况下，NT F参数为1，表示主干分成两个子干。<br />图15中的樱桃树具有四个分支级别（NL = 4）。φF IB和φSIB的系数指示了曲线的陡峭程度。在这种情况下，第一个向后弯曲，而其他分支级别向相反方向弯曲。前三个分支级别的顶端曲率与树干基底的曲率相同，而最后一个分支级别的顶端曲率与其基底曲率相同。在这种情况下，树干分为两部分，所有级别的分支吸引点都朝上。最后，CBH指示樱桃树约50%没有分支，这与BD参数一致。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706692735004-f81f074e-73df-4ca2-93e4-5511c6469305.png#averageHue=%23f8f6f4&clientId=u09922142-6bf1-4&from=paste&height=243&id=ue585188f&originHeight=304&originWidth=791&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=70974&status=done&style=none&taskId=u1192c52f-c22d-40e3-ad2c-13f4c09bc1b&title=&width=632.8)<br />Figure 16: 盆景树SG草图的示例。φF IB和φSIB参数的不一致符号表示主干和第一级分支的S形状。<br />图16中显示的盆景树也有四个分支级别（NL = 4）。盆景的树干没有分叉，由NT F参数指示，而且也呈S形，如φF IB和φSIB参数的不一致符号所示。第一级分支也呈S形，但在方向上与树干相对。事实上，其他分支级别的φF IB和φSIB都为负，因此这些分支的基底和顶端都朝前弯曲。此外，20%的樱桃树没有分支，而所有分支级别都向上吸引，分别由CBH和GBS参数确认。
<a name="j6do8"></a>
## 6 结论和未来工作
我们提出的方法可以使用深度学习方法预测3D树木网格生成的参数。主要目标是通过在建造3D树木的建模软件的模型师和建模软件之间引入一个经纪系统来自动化程序建模。我们的经纪的核心是基于卷积的深度神经网络，我们称之为TreeSketchNet，它使用监督方法进行训练，以学习众所周知的Weber-Penn树参数与树的2D草图之间的映射关系。由于需要大量的训练和验证数据集，我们开发了一个专门的RT Blender插件。这个插件使得能够自动化生成逼真的SG草图，从而生成预先使用一组固定和非固定的随机控制参数生成的3D树木网格。这种方法被实施来克服生成昂贵的HM数据集的图纸的问题。为了实现我们的实验目的，我们考虑了5种树木物种（枫树、松树、盆景、棕榈树和樱桃树），并从前、后、左和右的摄像机角度创建相应的草图。我们通过受控实验评估了我们的系统和所获得的结果。具体而言，我们要求参与者根据在两分钟内展示的参考SG示例制作HM草图，并用它们来测试系统。结果是令人鼓舞的，我们相信这可能是未来研究的起点。我们的实验还突显了高度的泛化水平，并验证了我们方法的准确性。此外，我们尝试了几种其他核心网络，以确定最适合且性能最好的选项。值得注意的是，我们测试了在计算机视觉任务中广泛使用并赢得了ILSVRC比赛[103]的AlexNet，它成为深度学习领域的最新技术。AlexNet是唯一在类似的草图到网格参数方法中使用的DNN[4]。然而，它的性能不如Efficientnet-B7，因此被舍弃。最后，我们提供了对结果的定性分析，具体而言，是对预测参数与其对应输入草图的视觉比较。我们的结果表明，与图像到网格或体素相比，基于我们的过程建模的方法在粗糙和光滑表面、伪像、孔洞以及变形或不必要的多边形方面更好。由于我们的结果是令人鼓舞的，我们计划继续研究基于过程建模和深度学习的草图到3D网格方法。实际上，我们的方法是从手绘草图生成3D树模型的基线。我们证明了通过为绘制草图的用户提供一些绘制指南，TSN可以获得与输入草图一致的结果。显然，正如[68]所肯定的那样，一旦用户画出与训练集中的草图非常不同的树，该方法就存在局限性。我们计划探索使用不同风格的草图来使我们的方法更具通用性。在未来的工作中，我们可以扩大树种的数量和/或通过将我们的方法适应到其他上下文，如花瓶、椅子、建筑、家具等，生成新的3D网格。[4]。此外，在未来的工作中，我们希望定义一种纹理生成方法，该方法可以避免使用用于从预定义集中选择最合适纹理的树种识别算法1。可能的方法是考虑有彩色的输入草图，并从中提取纹理或颜色。此外，这种方法可以用作实时生成3D树或3D环境的应用程序的起点。另一个未来的工作可以使用我们的方法从草图生成3D模型，并用它来制作卡通风格的视频，进行网格到图像合成。
<a name="C2huq"></a>
### 6.1 讨论和局限性
我们的方法自动化了通过从草图预测参数进行程序建模的原因有几个，被证明是生成复杂3D模型（如树木）的最佳选择之一。其中一个原因是直接使用图像作为DNN输入预测网格的方法通常存在定性问题[46, 50, 104]，如粗糙和光滑的表面、伪像、孔洞以及变形和不必要的多边形，特别是对于树干和分支这样的薄层结构。此外，从直接方法生成的3D网格通常与输入RGB图像或草图的外观差异较大。程序建模方法可以克服这些问题，用于生成3D网格的方法[17, 18, 19]。另一个优点是3D网格始终是正确的，因为我们的强大的RT Blender插件正确解释参数并使用它们，避免了产生伪像和错误的生成。后者通过我们的TSN的参数的预测准确性来证明，即使在困难的条件下，如在第5.1节中报告的。尽管程序建模在深度学习和人工智能领域中只是最近被探索[19, 105, 106]，但迄今为止，尚无太多专门的方法来研究3D非线性内容生成的预测参数，无论是植物总体上，还是树木[51, 67]特别是。我们将我们的基线（参见第5.2节）与更为人熟知的核心网络进行了比较，以评估我们工作的有效性。为了进一步评估TSN的性能，我们使用HDD度量提供了定量分析。通过可视化定性分析（见第5.4节），我们还评估了预测参数与提供给TSN的草图的一致性，对于一些易于理解和视觉识别的参数。此外，我们使用Hausdorff距离比较了从预测参数生成的3D树网格与ground-truth网格，如第5.3节所述。为了测试我们方法的鲁棒性，我们进行了一些额外的具有挑战性的实验。具体而言，我们使用包含破碎段的草图图像测试了我们的TSN。图17显示了两个具有删除部分的树草图的示例。在图17的第一行中，可以看到重建的树在草图的裁剪区域的分支较少，而ground-truth则有更多的分支。图17的一行显示了一棵缺少一个环的松树的草图。因此，TSN预测的松树环比ground-truth少一个。图18报告了由于实验参与者提供的输入草图的精度较差而引起的两个离群值。图18的前两幅图像代表了枫树的HM草图及其相对的3D模型。草图代表了一棵带有很少分支的树，用非常细的线绘制。因此，TSN预测了一棵分支较少的枫树，叶子分布在树枝上。因此，输出树的冠比草图更光秃，而预测的树枝与草图的树枝相似。图18的最后两幅图显示了另一个有趣的行为。在这里，树枝没有画得很好，所以TSN试图根据树干和冠提供的信息预测树的形状。结果是一个3D网格，与输入草图不太相似，但与树种和主要可见元素一致。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706693632845-3b0cdeea-9a5a-45ec-8280-af5b4b2c622b.png#averageHue=%23f4f4f4&clientId=u09922142-6bf1-4&from=paste&height=237&id=u093ccbc7&originHeight=296&originWidth=795&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=99359&status=done&style=none&taskId=u18b9491c-f319-4ff2-aa94-3bb3645e25c&title=&width=636)<br />Figure 17: 给出缺失区域草图的TSN的结果。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706693643421-ff708739-4394-4738-8f28-33a794afc161.png#averageHue=%23eceaea&clientId=u09922142-6bf1-4&from=paste&height=131&id=ue6c624e4&originHeight=164&originWidth=775&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=60436&status=done&style=none&taskId=u9d7e189e-649e-441c-a88f-d0a14b4c26d&title=&width=620)<br />Figure 18: 在受控实验中的异常值示例。

为了获得关于TSN认为哪些草图细节是强制性的更明显的指示，我们提出了另一个实验。这包括测试TSN对于具有不同完整性级别（LOC）的HM草图的鲁棒性。为了进一步测试我们的TSN，我们决定绘制五棵具有不同LOC的枫树，因为在这个物种中TSN返回的结果不太准确。图19显示了这个实验的结果。比较前两列，如果草图中没有冠并且树干和树枝没有厚度（第二列），TSN在预测第二级分支时会更加困难。这是因为训练集只包含具有不同厚度表示的树冠树的草图。因此，当将第二列的草图作为TSN的输入时，TSN无法理解分支属于哪个级别。另一方面，第三列和第四列的草图包含比第二列草图更多的信息。特别是，第三列的草图还包含关于冠的信息，而第四列的草图包含关于树干和树枝的厚度的信息。因此，TSN生成了与输入草图相似的树木。从所有这些中可以得出结论，TSN能够在草图具有与最后一列草图相同绘制风格时获得更好的结果。观察图19中的结果，可以注意到如果草图中包含比其他分支更弯曲的分支，则TSN倾向于使其他分支的弯曲度均匀化。<br />通过从先前的实验中获得的信息，清楚地表明有必要为参与者提供一些绘制HM草图的指南。尽管我们的工作提供了一个基于明确定义参数生成3D树的流水线，但其中之一的局限性是考虑的树种数量较少。然而，通过在未来的情景中考虑更多的物种，可以轻松克服这一局限性。所提出的方法基于Weber-Penn方法，因为它是稳定的，并已实施为Blender插件。尽管如此，由于TSN的最后一部分的结构，它可以适应其他较新的程序建模方法[31]。实际上，只需将新方法的每个参数排序到网络最后一层的相应值范围的分支中，然后使用以前学到的权重作为新培训的起点，就可以实现这一点。<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/34239894/1706693751067-b139e34c-c676-438b-b29f-29bb29c33551.png#averageHue=%23edebeb&clientId=u09922142-6bf1-4&from=paste&height=214&id=u99de4bab&originHeight=268&originWidth=796&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=88312&status=done&style=none&taskId=ue111a8d5-8656-49e9-8420-f77f8181891&title=&width=636.8)<br />Figure 19: 具有不同完整性水平（LOC）的HM草图实验
<a name="YWAWN"></a>
## 7 在线资源
我们已通过GitHub存储库共享了我们的RT Blender插件、DNN源代码和训练好的权重: [https://github.com/Unibas3D/TreeSketchNet](https://github.com/Unibas3D/TreeSketchNet)。此外，作者愿意在通过电子邮件向他们发送请求的情况下分享训练数据集。最后，我们在GitHub页面中包含了一个说明性视频。
