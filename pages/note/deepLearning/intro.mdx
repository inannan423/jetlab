# 机器学习介绍

## 显著式编程和非显著式编程

例如我我们要编写程序，让计算机通过图片区分玫瑰和菊花，我们可以编写程序，明确红色的是玫瑰，黄色的是菊花，以此来区分。这种编程方式叫做显著式编程。

但是如果我们给计算机程序一堆玫瑰和菊花的图片，让计算机自己学习，然后自己总结出玫瑰和菊花的区别，这种编程方式叫做非显著式编程。

显著式编程的优点是，我们可以很容易的理解程序，但是缺点是，我们需要自己去总结规律，然后编写程序，这样的程序很容易出错，而且我们总结的规律可能不是最优的。而非显著式编程的优点是，我们不需要自己总结规律，而是让计算机自己总结规律。在复杂的问题中，我们很难总结出规律，而计算机可以通过大量的数据，总结出规律，这样的规律可能是最优的。

又有一个例子，有一个机器人，为我们服务，到服务大厅取咖啡，通过显著式编程，我们可以编写程序，让机器人先左转，然后再右转，然后取咖啡，然后再左转，然后再右转，然后再回到我们身边。但是这样显然不是最优的方法。通过非显著式编程，我们赋予每个动作一个收益函数，例如机器人摔倒了，收益函数为负，机器人取到咖啡了，收益函数为正，机器人撞到了墙，收益函数为负，然后我们让机器人自己学习，通过大量的尝试，总结出最优的方法。

![](https://jetzihan-img.oss-cn-beijing.aliyuncs.com/20231217214914.png)

## 定义

1998 年 Tom Mitchell 给出了机器学习的定义：

> A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.

翻译过来就是：

> 机器学习是指，计算机程序在某类任务 T 上，通过经验 E，以性能度量 P 表现出随着经验 E 的增长而提升的性能。

还是上面的玫瑰和菊花的例子。

- 任务 T：区分玫瑰和菊花
- 经验 E：给计算机一堆玫瑰和菊花的图片
- 性能度量 P：计算机区分玫瑰和菊花的准确率

当训练的玫瑰和菊花的图片越多，计算机区分玫瑰和菊花的准确率越高，这就是机器学习。

在机器人取咖啡的例子中：

- 任务 T：取咖啡
- 经验 E：机器人的动作
- 性能度量 P：机器人的收益函数

这种效果在显著式编程中很难实现。

## 机器学习的分类

假如有四个任务：

- 任务 A：教计算机下棋
- 任务 B：教计算机识别邮件中的垃圾邮件
- 任务 C：人脸识别
- 任务 D：自动驾驶

这四个任务按照经验 E 可以分为两类：

- 任务 B 和任务 C： 人为总结大量的经验 E，让计算机自己总结规律，这种方式叫做**监督学习**。
- 任务 A 和任务 D：经验 E 是计算机和环境的交互中获得的，我们给定收益函数，对行为进行奖励或者惩罚，让计算机改变行为模式来最大化收益，这种方式叫做**强化学习**。

由于监督学习需要人为总结大量的经验 E，因此出现了一种行业，专门从事人为总结经验 E，这种行业叫做**数据标注**。

实际上，两者并不是互斥的，且可以相互合作，如 AlphaGo，在早期学习了很多围棋大师的棋谱，然后通过强化学习，不断提升自己的水平。

![](https://jetzihan-img.oss-cn-beijing.aliyuncs.com/20231217214204.png)

## 监督学习的分类

监督学习按照训练数据的类型，可以分为三类：

- 传统监督学习（Traditional Supervised Learning）：每一个训练的数据都有相应的标签。涉及的算法有：
    - 支持向量机（Support Vector Machine）
    - 人工神经网络（Neural Network）
    - 深度神经网络（Deep Neural Network）
- 非监督学习（Unsupervised Learning）：每一个训练的数据都没有相应的标签。
    - 聚类（Clustering）
    - EM 算法（Expectation Maximization）
    - 主成分分析（Principal Component Analysis）
- 半监督学习（Semi-supervised Learning）：部分训练的数据有相应的标签，部分训练的数据没有相应的标签。随着互联网的普及，互联网中出现了大量的数据，但是数据标注成本很高，因此我们希望通过少量的数据标注，然后通过半监督学习，来提升整体的性能。

按照标签是否是离散的，可以分为两类：

- 分类（Classification）：标签是离散的，例如垃圾邮件和非垃圾邮件。
- 回归（Regression）：标签是连续的，例如房价。

## 机器学习算法的过程

![](https://jetzihan-img.oss-cn-beijing.aliyuncs.com/20231217214851.png)

如要识别尿样本中的白细胞和红细胞主要步骤如下：

- 特征提取，例如红细胞和白细胞的面积、周长、圆形度等。
- 特征选择，哪些特征对于区分红细胞和白细胞是有用的，哪些特征对于区分红细胞和白细胞是无用的。比如说，我们发现面积和周长对于区分红细胞和白细胞作用明显，但是圆形度对于区分红细胞和白细胞作用不明显。因此我们选择面积和周长作为特征。
- 训练模型，例如我们选择支持向量机作为模型。我们将红细胞和白细胞画到一张二维图上，横坐标代表面积，纵坐标表示周长，我们可以在二维图中画一条直线，来划分红白细胞，之后就可以根据这条线完成区分。至此，机器学习的过程就结束了。

![](https://jetzihan-img.oss-cn-beijing.aliyuncs.com/9179a96dd9575590e94ffa5c7a4de9a.jpg)

很简单嘛？画这条线人类不都可以做到？并不是，因为这里只有两个维度，我们可以很容易的画出一条直线，但是如果有三个维度，我们就需要画一个平面，如果有四个维度，我们就需要画一个立体，如果有五个维度，我们就需要画一个五维的图形，这样的图形我们无法想象，更不用说画出来了。因此，通过机器学习，我们可以很容易的完成多维度的分类。

我们总结一下机器学习的过程：

- 特征提取
- 特征选择
- 选择机器学习算法
- 训练模型

## 没有免费的午餐定理

1995 年 David Wolpert 提出了没有免费的午餐定理：

> 任何一个预测函数，如果在一些训练样本上表现得很好，那么在另外一些训练样本上表现得就很差，反之亦然。如果不对学习算法的先验知识进行假设，那么所有的学习算法的期望性能是相同的。

我们不能夸大这个定理的作用，对开发新的机器学习算法丧失信心。

## 学习完机器学习之后，你能做什么？

如：

- 人脸识别
- 语音识别
- 五子棋对战
- 自动驾驶
- 人脸性别和年龄估计
